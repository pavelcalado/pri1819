\documentclass[12pt]{article}

\usepackage{prilab}
\usepackage{url}


\begin{document}

\maketitle{Lab 08: Crawling the Web}

The goal of this exercise is to implement a simple Web crawler.

\section{}

Implement a crawler that takes as input a list of seed URL and collects Web
pages starting from there. The collection should be done in a
\textbf{breadth-first} manner. Each collected page should be stored in a
separate HTML file.

\begin{quote}
    \textbf{Notes:}
    \begin{itemize}
    \item We can use any naming convention you wish for the files (e.g. use a
        unique number for each file);
    \item To get a page from the Web you can use the \texttt{urllib2}
        module. For example:
\begin{verbatim}
from urllib2 import urlopen
site = urlopen("http://www.ist.utl.pt")
content = site.read()
print content
site.close()
\end{verbatim}
    \item You can collect anchor links from the HTML page using regular
        expressions. For example:
\begin{verbatim}
import re
linksre = '<a\s.*?href=[\'"](.*?)[\'"].*?</a>'
links = re.findall(linksre, content, re.I)
\end{verbatim}
    \item You can use the \texttt{urlparse} module to transform relative links
        into absolute links. For example:
\begin{verbatim}
import urlparse
url = urlparse.urljoin("http://www.ist.utl.pt/", "eventos/")
print url
\end{verbatim}
    \item After transforming the links to absolute links, consider only those
        that start with ``http'';
    \item Do not worry about transforming the URL into their canonical form;
    \item Make sure you do not collect the same link twice;
    \item You will want to \textbf{limit the depth} of the collection;
    \item Make sure you wait at least one second before each server
        request. For example, you can use the \texttt{time} module:
\begin{verbatim}
import time
time.sleep(1)
\end{verbatim}
    \item You can use the \texttt{robotparser} module to interpret the
        \emph{robots.txt} file. For example:
\begin{verbatim}
import robotparser
rp = robotparser.RobotFileParser("http://www.ist.utl.pt/robots.txt")
rp.read()
print rp.can_fetch("*", "http://www.ist.utl.pt/pt/candidatos/")
print rp.can_fetch("*", "http://www.ist.utl.pt/newscache/")
\end{verbatim}
        Note that the \emph{robots.txt} file usually only exists at the root of
        the server being accessed. The \texttt{RobotFileParser} class will not
        check if the file exists.
    \item \textbf{Remember:} some servers may block you, if you are not nice!
    \end{itemize}
\end{quote}


\section{}

Modify you crawler, to create a vertical crawler. It should take as input a
list of keywords, representing a topic (e.g. ``peer to peer networks'') and
collect only pages within that topic.

To decide if a page is related to the given topic, you can simply count how
many of the topic words it contains and set a decision threshold (e.g. if it
contains at least $2/3$ of the topic words, it should be collected).

\section{}

Index the collected pages using Whoosh. Make sure you store the URL of each
page. You may need to modify your crawler, to also store the URL. 

Create a script that allows a user to perform searches. The result of a search
should be a list of URL, sorted according to the page relevance. Together with
each URL, there should be a text snippet for the page. 

See the Whoosh documentation on how to present text snippets, at
\url{http://whoosh.readthedocs.io/en/latest/highlight.html}.

\section{Pen and Paper Exercises}

\begin{enumerate}
\item Compute the Jaccard similarity of each pair of the following sets: 

\begin{itemize}
\item $\{1, 2, 3, 4, 5\}$
\item $\{1, 6, 7\}$
\item $\{2, 4, 6, 8\}$
\end{itemize}

\item Suppose that you want to use the min-hash scheme for representing sets of items, in which there are ten different items that can be used within the sets (i.e., the universal item set is $\{ 1, 2, \ldots , 10\}$). Suppose also that the min-hash signatures for the sets are constructed using the following list of permutations for the universal set:

\begin{itemize}
\item $(1,2,3,4,5,6,7,8,9,10)$ 
\item $(10,8,6,4,2,9,7,5,3,1)$ 
\item $(4,7,2,9,1,5,3,10,6,8)$
\end{itemize}

Construct minhash signatures for the following sets: 

\begin{itemize}
\item $\{3,6,9\}$
\item $\{2,4,6,8\}$
\item $\{2,3,4\}$
\end{itemize}

\item Suppose that instead of using particular permutations to construct the min-hash signatures for the three sets of the previous problem, we use an efficient single-pass implementation leveraging hash functions to construct the signatures. The three hash functions we use are as follows:

\begin{itemize}
\item $f(x)=x \mathrm{mod} 10 $
\item $g(x)=(2x+1) \mathrm{mod} 10$
\item $h(x)=(3x+2) \mathrm{mod} 10$
\end{itemize}

Compute the signatures for the three sets, and compare the resulting estimate of the Jaccard similarity of each pair with the true Jaccard similarity.

\item The function $p = 1 − (1 − s^r)^b$ gives the probability $p$ that two min-hash signatues that come from sets with Jaccard similarity $s$ will hash to the same bucket at least once, if we use an LSH scheme with $b$ bands of $r$ rows each. For a given similarity threshold $s$, we want to choose $b$ and $r$ so that $p = 1/2$ at $s$. Suppose signatures have length 24, which means we can pick any integers $b$ and $r$ whose product is $24$ (i.e., the choices for $r$ are 1, 2, 3, 4, 6, 8, 12, or 24, and $b$ must then be $24/r$). If $s = 1/2$, determine the value of $p$ for each choice of $b$ and $r$, and state which value would you choose for $r$ to maximize result quality.
\end{enumerate}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

