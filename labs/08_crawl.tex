\documentclass[12pt]{article}

\usepackage{prilab}
\usepackage{url}


\begin{document}

\maketitle{Lab 08: Crawling the Web + Similarity Search}

The goal of this exercise is to implement a simple Web crawler.

\section{}

Implement a crawler that takes as input a list of seed URL and collects Web
pages starting from there. The collection should be done in a
\textbf{breadth-first} manner. Each collected page should be stored in a
separate HTML file.

\begin{quote}
    \textbf{Notes:}
    \begin{itemize}
    \item We can use any naming convention you wish for the files (e.g. use a
        unique number for each file);
    \item To get a page from the Web you can use the \texttt{urllib2}
        module. For example:
\begin{verbatim}
from urllib2 import urlopen
site = urlopen("http://www.ist.utl.pt")
content = site.read()
print content
site.close()
\end{verbatim}
    \item You can collect anchor links from the HTML page using regular
        expressions. For example:
\begin{verbatim}
import re
linksre = '<a\s.*?href=[\'"](.*?)[\'"].*?</a>'
links = re.findall(linksre, content, re.I)
\end{verbatim}
    \item You can use the \texttt{urlparse} module to transform relative links
        into absolute links. For example:
\begin{verbatim}
import urlparse
url = urlparse.urljoin("http://www.ist.utl.pt/", "eventos/")
print url
\end{verbatim}
    \item After transforming the links to absolute links, consider only those
        that start with ``http'';
    \item Do not worry about transforming the URL into their canonical form;
    \item Make sure you do not collect the same link twice;
    \item You will want to \textbf{limit the depth} of the collection;
    \item Make sure you wait at least one second before each server
        request. For example, you can use the \texttt{time} module:
\begin{verbatim}
import time
time.sleep(1)
\end{verbatim}
    \item You can use the \texttt{robotparser} module to interpret the
        \emph{robots.txt} file. For example:
\begin{verbatim}
import robotparser
rp = robotparser.RobotFileParser("http://www.ist.utl.pt/robots.txt")
rp.read()
print rp.can_fetch("*", "http://www.ist.utl.pt/pt/candidatos/")
print rp.can_fetch("*", "http://www.ist.utl.pt/newscache/")
\end{verbatim}
        Note that the \emph{robots.txt} file usually only exists at the root of
        the server being accessed. The \texttt{RobotFileParser} class will not
        check if the file exists.
    \item \textbf{Remember:} some servers may block you, if you are not nice!
    \end{itemize}
\end{quote}


\section{}

Modify you crawler, to create a vertical crawler. It should take as input a
list of keywords, representing a topic (e.g. ``peer to peer networks'') and
collect only pages within that topic.

To decide if a page is related to the given topic, you can simply count how
many of the topic words it contains and set a decision threshold (e.g. if it
contains at least $2/3$ of the topic words, it should be collected).

\section{}

Index the collected pages using Whoosh. Make sure you store the URL of each
page. You may need to modify your crawler, to also store the URL. 

Create a script that allows a user to perform searches. The result of a search
should be a list of URL, sorted according to the page relevance. Together with
each URL, there should be a text snippet for the page. 

See the Whoosh documentation on how to present text snippets, at
\url{http://whoosh.readthedocs.io/en/latest/highlight.html}.

\section{Pen and Paper Exercises}

\begin{enumerate}
\item Compute the Jaccard similarity of each pair of the following sets: 

\begin{itemize}
\item $\{1, 2, 3, 4, 5\}$
\item $\{1, 6, 7\}$
\item $\{2, 4, 6, 8\}$
\end{itemize}

% SOLUTION
% J({1,2,3,4,5},{1,6,7}) = 1/7
% J({1,2,3,4,5},{2,4,6,8}) = 2/7
% J({1,6,7},{2,4,6,8}) = 1/6

\item Suppose that you want to use the min-hash scheme for representing sets of items, in which there are ten different items that can be used within the sets (i.e., the universal item set is $\{ 1, 2, \ldots , 10\}$). Suppose also that the min-hash signatures for the sets are constructed using the following list of permutations for the universal set:

\begin{itemize}
\item $(1,2,3,4,5,6,7,8,9,10)$ 
\item $(10,8,6,4,2,9,7,5,3,1)$ 
\item $(4,7,2,9,1,5,3,10,6,8)$
\end{itemize}

Construct minhash signatures for the following sets: 

\begin{itemize}
\item $\{3,6,9\}$
\item $\{2,4,6,8\}$
\item $\{2,3,4\}$
\end{itemize}

%SOLUTION: Each of the 3 values in the signatures is the first value in the permutation that appears in the subset. Hence the three signatures are:
%(a) (3,6,9) 
%(b) (2,8,4) 
%(c) (2,4,4)

\item Suppose that instead of using particular permutations to construct the min-hash signatures for the three sets of the previous problem, we use an efficient single-pass implementation leveraging hash functions to construct the signatures. The three hash functions to be used are as follows:

\begin{itemize}
\item $f(x)=x ~\mathrm{mod}~ 10 $
\item $g(x)=(2x+1) ~\mathrm{mod}~ 10$
\item $h(x)=(3x+2) ~\mathrm{mod}~ 10$
\end{itemize}

Compute the signatures for the three sets, and compare the resulting estimate of the Jaccard similarity of each pair with the true Jaccard similarity.

%SOLUTION: Instead of finding the first value in the permutation that appears in the subset, we compute the minhash as the smallest value of the hash function in the whole subset. This yields the following three signatures:
%
%(a) (3,3,0) 
%(b) (2,3,0) 
%(c) (2,5,1)
%
%To estimate the Jaccard similarity from a minhash vector (derived either from permutations or hash functions), we find the number of matching minhash values in corresponding positions in the two subsets’ minhash vectors. Estimating the Jaccard similarity using both permutation minhash vectors and hash function minhash vectors gives:
%
%Set 1                Set 2            Actual J    Hash est. J   Perm. est. J
%(a) {3,6,9}          (b) {2,4,6,8}    1/6         2/3           0/3
%(a) {3,6,9}          (c) {2,3,4}      1/5         0/3           0/3
%(b) {2,4,6,8}        (c) {2,3,4}      2/5         1/3           2/3
%
%We can see that these minhash vectors, whether computed from universal set permutations or a list of hash functions, are quite poor estimators of the Jaccard similarity. This is understandable given how short the minhash vectors actually are. We should get more permutations of the universal set or more hash functions to make the minhash vectors longer.

\item The function $p = 1 - (1 - s^r)^b$ gives the probability $p$ that two min-hash signatues that come from sets with Jaccard similarity $s$ will hash to the same bucket at least once, if we use an LSH scheme with $b$ bands of $r$ rows each. For a given similarity threshold $s$, we want to choose $b$ and $r$ so that $p = 1/2$ at $s$. Suppose signatures have length 24, which means we can pick any integers $b$ and $r$ whose product is $24$ (i.e., the choices for $r$ are 1, 2, 3, 4, 6, 8, 12, or 24, and $b$ must then be $24/r$). If $s = 1/2$, determine the value of $p$ for each choice of $b$ and $r$, and state which value would you choose for $r$ to maximize result quality.

%SOLUTION:
% r = 1,b = 24: p = 1−(1−(1/2)1)24 = 1−(1/2)24 ≈ .99999994 
% r = 2,b = 12: p = 1−(1−(1/2)2)12 = 1−(3/4)12 ≈ 0.968
% r = 3,b = 8: p = 1−(1−(1/2)3)8 = 1−(7/8)8 ≈ .657
% r = 4,b = 6: p = 1−(1−(1/2)4)6 = 1−(15/16)6 ≈ .321
% r = 6,b = 4: p = 1−(1−(1/2)6)4 = 1−(63/64)4 ≈ .0611
% r = 8,b = 3: p = 1−(1−(1/2)8)3 = 1−(255/256)3 ≈ .0117
% r = 12,b = 2: p = 1−(1−(1/2)12)2 = 1−(2047/2048)2 ≈ 4.882·10^−4
% r = 24,b = 1: p = 1−(1−(1/2)24)1 = 1−(16777215/16777216)1 ≈ 5.960 · 10^−8
%It’s clear that, in this case, you should choose to minimize the number of rows (positions within a signature), by letting r = 1.

\end{enumerate}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

